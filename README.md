# neuralNetwork

## Overview

This repository contains various neural network models and implementations for different machine learning tasks. Each folder represents a distinct project or concept in neural networks, with its own specific implementation and functionality.

---

## Folder Structure

### 1. **ADALINE**
   - **Description**: 
     Contains the implementation of the ADALINE (Adaptive Linear Neuron) model for digit classification using the MNIST dataset.
   - **Key Features**:
     - Trains individual ADALINE units to recognize digits (0-9).
     - Plots error graphs for each digit during training.
     - Provides accuracy metrics for test data.
     - 
### 2. **MLP-Backpropagation**
   - **Description**:
     This project demonstrates the implementation of a Multi-Layer Perceptron (MLP) using backpropagation for training. The network supports multiple hidden layers and is capable of learning complex patterns in data.
   - **Key Features**:
      - Implements backpropagation for efficient training of MLP networks.
      - Supports customizable architectures with configurable numbers of hidden layers and neurons.
      - Includes adjustable parameters like learning rate, activation functions, and epochs for fine-tuning the model.

### 3. **Multi-class-classifier**
   - **Description**:
     The project demonstrates the use of perceptrons for multi-class classification. Each perceptron is trained to recognize one specific class. Classes can be represented as binary patterns or multi-dimensional feature vectors.
   - **Key Features**:
      - Trains perceptrons to classify data into multiple categories.
      - Supports parameter tuning, such as learning rate and epochs.
      - Can be extended for complex datasets and advanced classification tasks

---
